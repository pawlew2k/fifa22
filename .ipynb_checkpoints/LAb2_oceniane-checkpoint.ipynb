{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2dbe6d-7ffe-49e9-83ff-c9a392f8ddbf",
   "metadata": {},
   "source": [
    "# Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb79d7-0b8d-4ddc-ac90-91995744b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5c929-d7b4-4785-9803-da9309113299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file.csv', sep = ';')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c88a2e7-3e9b-4c1c-9880-2944a08eb1d9",
   "metadata": {},
   "source": [
    "# Test Fishera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e06767-1465-4bce-8cba-b19f0984d99a",
   "metadata": {},
   "source": [
    "W teście stawiamy hipotezę że wariancje dwóch rozkładów są sobie równe\n",
    "$\\sigma_t^2$ = $\\sigma_v^2$\n",
    "Test działa poprawnie na zmiennych o rozkładzie normalnym.\n",
    "Statystyka F-testu może być wyliczona jako stosunek dwóch\r\n",
    "wariancji\n",
    "$F = S_t^2/S_v^2 e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a02b6-780d-49cc-8c75-379d0802a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def f_test(x, y, alt=\"two_sided\"):\n",
    "    # Test Fishera równości wariancji rozkładów\n",
    "    # Parametry:\n",
    "    # x   - próbka pierwszego rozkładu\n",
    "    # y   - próbka drugiego rozkładu\n",
    "    # alt - hipoteza alteratywna\n",
    "    # Wyniki (krotka):\n",
    "    # - stosunek wariancji obu rozkładów\n",
    "    # - prawdopodobieństwo testowe\n",
    "    df1 = len(x) - 1\n",
    "    df2 = len(y) - 1\n",
    "    f = x.var() / y.var()\n",
    "    if alt == \"greater\": # hipoteza alternatywna wariancja x większa od wariancji y\n",
    "        p = 1.0 - stats.f.cdf(f, df1, df2) # cdf  - Funkcja rozkładu skumulowanego.\n",
    "    elif alt == \"less\": # hipoteza alternatywna wariancja x mniejsza od wariancji y\n",
    "        p = stats.f.cdf(f, df1, df2)\n",
    "    else: # hipoteza alternatywna wariancja x różna od wariancji y\n",
    "        p1 = 1.0 - stats.f.cdf(f, df1, df2)\n",
    "        p2 = stats.f.cdf(f, df1, df2)\n",
    "        p = 2*min(p1, p2)\n",
    "    return round(f,2), round(p,2) # f - stosunek wariancji obu rozkładów, p - prawdopodobieństwo hipotezy alternatywnej"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05a5613-927e-435c-b22e-e376ec9ec6a8",
   "metadata": {},
   "source": [
    "Dla danych z pliku porównaj wariancje zmiennej ciężar_max z pozostałymi\n",
    "zmiennymi.\n",
    "Sprawdź, czy prawdopodobieństwo testowe pozwala na odrzucenie hipotezy zerowej i\n",
    "przyjęcie, ze któraś ze zmiennych ma wariancje rożną od ciężar_max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c6e97-4751-42a6-96e4-fb8f1f0ac70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns[2:]:\n",
    "    f, p = f_test(df['ciężar_max'], df[col])\n",
    "    print(f'{col}\\t{f}\\t{p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f22d3b-2115-49ac-b38b-de88b579e9ee",
   "metadata": {},
   "source": [
    "Sprawdź, czy prawdopodobieństwo testowe pozwala na odrzucenie hipotezy zerowej i\n",
    "przyjęcie, ze któraś ze zmiennych ma wariancje mniejszą od ciężar_max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20b11b-398d-4336-a422-d7761d77c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns[2:]:\n",
    "    f, p = f_test(df['ciężar_max'], df[col], 'greater')\n",
    "    print(f'{col}\\t{f}\\t{p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8198e25-742d-41b5-9aa1-4490c65ab594",
   "metadata": {},
   "source": [
    "Sprawdź, czy prawdopodobieństwo testowe pozwala na odrzucenie hipotezy zerowej i\n",
    "przyjęcie, ze któraś ze zmiennych ma wariancje większą od ciężar_max. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02800c-5f8b-4a7e-828f-855933c04952",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns[2:]:\n",
    "    f, p = f_test(df['ciężar_max'], df[col], 'less')\n",
    "    print(f'{col}\\t{f}\\t{p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc95a1-5210-4755-bf83-edfb8771f30f",
   "metadata": {},
   "source": [
    "Czy zmiana hipotezy alternatywnej zmienia uzyskane wyniki?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b12240-0c47-4f58-81f5-2ff581bb5c64",
   "metadata": {},
   "source": [
    "Zmienia, suma wartości p greater i less wynosi 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e436745-2891-4f5e-9e4b-5e6e12473ba1",
   "metadata": {},
   "source": [
    "# Analiza wariancji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6034d66-a365-4be3-a399-f15c2e78b419",
   "metadata": {},
   "source": [
    "Dla danych z pliku przeprowadź dla zmiennej Rodzina analizę wariancji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6ac78-57d0-4521-a791-c8a47df0d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc78126-59a9-4df7-9dcb-6334f9028271",
   "metadata": {},
   "source": [
    "# Test ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde71e8b-8fad-4a98-8468-2dd4a3abd7f9",
   "metadata": {},
   "source": [
    "W teście stawiamy hipotezę, że średnie dla rozkładu w każdej \n",
    "z n klas są takie same\n",
    "Wyliczenie statystyki opiera się na następujących krokach:\n",
    "    1. Wyliczenie wariancji wewnętrznej próbki $S_w^2$\n",
    "    2. Wyliczenie średniej dla każdej z klas\n",
    "    3. Wyliczenie wariancji pomiędzy średnimi $S_b^2$\n",
    "Statystyka może być wyliczona jako stosunek dwóch wariancji\n",
    "$F = S_b^2/S_w^2 $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fed7b-d5b5-40d2-90da-c81a8cd0f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('ciężar_max ~ Rodzina' ,data=df).fit()\n",
    "aov_table = anova_lm(model)\n",
    "print(aov_table)\n",
    "\n",
    "# sum_sq - Suma kwadratów dla warunków modelu.\n",
    "# mean_sq - Suma kwadratów/Stopnie swobody\n",
    "# df - Stopnie swobody dla warunków modelu.\n",
    "# F - Wartość statystyki F dla istotności dodania warunków modelu.\n",
    "# PR(>F) - P-value for significance of adding model terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a9793-2399-48f7-8f14-a4c0a99cff9f",
   "metadata": {},
   "source": [
    "# Test HSD Tukeya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1839eb-8788-4377-ab9a-4929acc3babd",
   "metadata": {},
   "source": [
    "Test HSD Tukeya (Tukey’s Honestly Significant Difference \n",
    "test) pozwala nam określić, bazując na wynikach z analiz \r\n",
    "wariancji, czy zmienna różni się znacząco między klasam\n",
    "Test wykorzystuje statystykę\n",
    "$q_s = (\\mu_A - \\mu_B)/SE $\n",
    "\n",
    "gdzie µA jest większą ze średnich µA, µB , a SE jest błędem \n",
    "standardowym sumy średnich\n",
    "\n",
    "Uzyskana wartość qs \n",
    "jest porównywana do krytycznej wartośc \r\n",
    "qα wynikającej z rozkładu t-Studen\n",
    "\n",
    "$q_\\alpha$ = (${\\bar {y}}_{max}$ - ${\\bar{y}}_{min}$ )/$S\\sqrt{2/n}$\n",
    "\n",
    "Załóżmy, że pobieramy próbę o rozmiarze n z każdej z k populacji o tym samym rozkładzie normalnym N(μ, σ2) i załóżmy, że \n",
    "${\\bar {y}}_{min}$ jest najmniejszą z tych średnich z próby i \n",
    "${\\bar {y}}_{max}$ jest największą z tych średnich z próby i załóżmy, że S2 jest łączną wariancją z tych prób..\r",
    ".i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b085c97-f82e-4c38-9342-86fb626d7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('ciężar_max ~ Rodzina' ,data=df).fit()\n",
    "tuk_table = pairwise_tukeyhsd(endog=df['ciężar_max'], groups = df['Rodzina'], alpha = 0.05)\n",
    "print(tuk_table)\n",
    "\n",
    "# endog - zmienna odpowiedzi\n",
    "# groups - tablica z grupami, może być ciągiem znaków lub liczbą całkowitą\n",
    "# alpha - poziom istotności dla testu\n",
    "\n",
    "# group 1 - grupa 1\n",
    "# group 2 - grupa 2\n",
    "# reject - array of bool, True if we reject Null for group pair\n",
    "# meandiff - spairwise mean differences\n",
    "# p-adj - p values adjusted p-values from the HSD test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d9baa-ae70-463a-82f4-53d9bf4dde37",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d989ad1-c8eb-4191-9a6d-033cf3d528f6",
   "metadata": {},
   "source": [
    "Dla regresji lasso wzór na estymator współczynników ma \n",
    "posta\n",
    "\n",
    "$\\hat{\\beta}_{lasso}$ = $argmin_{(\\alpha,\\beta)}(1/N){||\\alpha + X\\beta - y||}_2^2 + \\lambda||\\beta||_1$\n",
    "\n",
    "gdzie λ jest współczynnikiem funkcji kary regularyzacji, a N \n",
    "wielkością próbki uczącej\n",
    "Regresja LASSO pozwala uzyskać βi = 0..ć"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee58f069-6ea6-4760-bdde-49598177d857",
   "metadata": {},
   "source": [
    "Dla danych z pliku zbuduj model regresji LASSO objaśniając ciężar_max \n",
    "pozostałymi zmiennymi\n",
    "\n",
    "Wykreśl ścieżki LASSO dla utworzonego modelu.\n",
    "\r",
    " Określ, która zmienna zostanie wyeliminowana jako pierwsza.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d01c43-5756-4d6d-9aaf-4859b7815e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eeb284-4048-4484-b9bd-48dfeb8a8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'ciężar_max'\n",
    "features = [x for x in df.columns[2:] if x != label]\n",
    "\n",
    "l_min = -8 # lewy koniec zakresu przedziału lambd\n",
    "l_max = -1 # prawy koniec zakresu przedziału lambd\n",
    "l_num = 129 # liczba lambd\n",
    "lambdas = np.linspace(l_min,l_max, l_num) # lamda - współczynnik funkcji kary regularyzacji\n",
    "\n",
    "coefs = []\n",
    "for i in lambdas:\n",
    "   clf = Lasso(alpha=10**i) # deklaracja regresji Lasso\n",
    "   clf.fit(df[features],df[label]) # dopasowanie modelu Lasso do danych\n",
    "   coefs.append([i, *clf.coef_]) # zapisanie współczynników dla danej lambdy\n",
    "\n",
    "df_coefs = pd.DataFrame.from_records(coefs) # zapisanie dataframe z uzyskanych wyników\n",
    "df_coefs.columns = ['lambda', *features] # Kolumny\n",
    "df_coefs = df_coefs.set_index('lambda') # ustawienie indeksu \n",
    "df_coefs.plot() # wykreślenie wykresu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf297208-321b-42c6-b742-08f0f5b65910",
   "metadata": {},
   "source": [
    "# Drzewo decyzyjne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4756f92-60c7-4593-bbf5-b248e54ee513",
   "metadata": {},
   "source": [
    "Drzewo decyzyjne, w każdym węźle nie będącym liściem, dzieli analizowany zbiór na dwa podzbiory\n",
    "\n",
    "Podział odbywa się na podstawie zmiennej i progu dla jej wartości.\n",
    "\n",
    "Ponieważ celem jest uzyskanie, w liściach, zbiorów jednorodnych, to kryterium podziału musi maksymalizować rozróżnienie zbiorów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54d80e-6509-458c-8bf3-8ae60ae4656c",
   "metadata": {},
   "source": [
    "Dla danych z pliku fauna.csv zbuduj model klasyfikacyjny drzewa decyzyjnego przypisujący obserwacje do Rodzin.\n",
    "\n",
    "Wykreśl drzewo decyzyjne. Określ na podstawie drzewa, które zmienne będą istotne dla budowanego modelu.\n",
    "\n",
    "Zweryfikuj obserwacje na podstawie istotności cech zwracanych przez algorytm budowy drzewa.\n",
    "\n",
    "Która zmienna jest najbardziej, a która najmniej istotna? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88eda7-8219-4226-8ab1-6959493f555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9ae4f-e7f0-44f6-884b-a2fc3f44c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=1, max_depth=2) # Stworzenie klasyfikatora drzewa\n",
    "\n",
    "label = 'Rodzina'\n",
    "\n",
    "# Podział na zmienne X i Y\n",
    "X_train = df[df.columns[2:]] \n",
    "y_train = df[label]\n",
    "\n",
    "# Dopasowanie klasyfikatora drzew do danych\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "_ = plot_tree(clf, filled=True, rounded=True, label='all', feature_names=X_train.columns, class_names=clf.classes_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f6d23-b9e3-4be2-a820-2c8cc995570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = {'Feature': X_train.columns, 'Importance':clf.feature_importances_} # Wydobycie istotności cech\n",
    "feature_importances_df = pd.DataFrame.from_dict(feature_importances)\n",
    "print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf9a1e-a043-4d90-aedf-acd891462178",
   "metadata": {},
   "source": [
    "# Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990cb936-d676-40f2-857c-e90a440ef408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701d356c-3b08-402e-a523-6e0fff6b2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wifi.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83fa6a1-5729-4f5f-bebb-ea8c81b6854f",
   "metadata": {},
   "source": [
    "Wybranie tylko pierwszych dwóch kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61f2aa9-3dab-499b-b4aa-69037d16ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = df. iloc[:, 1:3]\n",
    "df12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bf563-d40f-462a-be66-4b49c04cb62b",
   "metadata": {},
   "source": [
    "Macierz kowariancji wyliczona domyslnie przez Pandasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5a8a1a-acb9-4863-8664-a60273938054",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdcov = df12.cov()\n",
    "pdcov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e2ad00-5a1d-4e7a-ac52-d365097c15bf",
   "metadata": {},
   "source": [
    "Macierz kowariancji wyliczona na podstawie danych (wierszy) bez braków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e01442-a146-4539-928f-d41a47f992fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcna = df12.dropna(how='any')\n",
    "dfcna.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f9594-f47c-4a20-9b05-09b870edde01",
   "metadata": {},
   "source": [
    "Macierz kowariancji korzystająca ze średnich ze wszystkich dostępnych danych w kolumnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2314b3d2-8f03-464a-9b19-995230105153",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [ df12['wifi 1'].mean(), df12['wifi 2'].mean()] # średnia dla obu kolumn\n",
    "cov2 = [[0,0],[0,0]]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(len(dfcna)):\n",
    "            cov2[i][j] += (dfcna.iloc[k,i]-m[i])*(dfcna.iloc[k,j]-m[j]) # suma różnic każdego z elementów ze średnią wartością pomnożone przez sumę różnic każdego z elementów ze średnią wartością\n",
    "        cov2[i][j] = cov2[i][j]/len(dfcna) # Podział przez liczbę elementów\n",
    "pd.DataFrame(cov2, columns=dfcna.columns,index=dfcna.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb71f3-d1a0-4e6a-bd40-4b296f8960e7",
   "metadata": {},
   "source": [
    "# Drzewo CART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82dabe0-a90e-421e-b9fd-46d19c339d95",
   "metadata": {},
   "source": [
    "W drzewach CART (Classification and Regression \n",
    "Tre)] współczynnik Ginnieg \r\n",
    "stosowany jest jako miara wariancji definiowanej dla węzła m i\r\n",
    "drzew  T j\n",
    "\n",
    "$Q_m(T) = I_G(m)$\n",
    "\n",
    "W przypadku podziału drzewo tworzy dwóch potomków mL \n",
    "and mR dla których można wyliczyć łączną wariancj\n",
    "\n",
    "$(n_{m_L}/n_m)Q_{m_L}(T) + (n_{m_R}/n_m)Q_{m_R}(T)$eako"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bcc8c9-6266-4099-9848-1a34f02cfe4a",
   "metadata": {},
   "source": [
    "Funkcja budująca drzewo CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b9a39-9d64-4212-85ab-357ef995b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Należy uzupełnić i odkomentować linie kodu\n",
    "def create_tree(x, y, depth=3, rnd_state=1):\n",
    "    clf = DecisionTreeRegressor(max_depth=depth, random_state=rnd_state) # deklaracja modelu drzewa CART\n",
    "    clf = clf.fit(x,y) #(dopasowanie modelu)\n",
    "    err = clf.predict(x)-y #(tablica błedów dla poszczególnych próbek)\n",
    "    MAE = round(np.mean(np.abs(err)),2) # Mean absolute error\n",
    "    RMSE = round(np.sqrt(((clf.predict(x)-y)**2).mean()),2) # Root Mean Squared Error\n",
    "    print(\"MAE:\", MAE, \"RMSE:\", RMSE)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfcffe0-8a15-4582-841c-a3a6a09bad59",
   "metadata": {},
   "source": [
    "Drzewo zbudowane na podstawie danych z usuniętymi wierszami z brakującymi danymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d46c48c-3506-47c8-88a3-fe06eae2ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.dropna()\n",
    "zad2 = create_tree(df2.iloc[:,1:], df2.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c335f6e8-7bb1-46d7-8644-10eca459c928",
   "metadata": {},
   "source": [
    "Drzewo zbudowane na podstawie danych z brakującymi danymi zastąpionymi wartością średnią"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e27b0-3cbb-446d-b983-e44bb52dc3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.fillna(df.mean())\n",
    "zad3 = create_tree(df3.iloc[:,1:], df3.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31feabfd-6081-4448-98b4-7456e46724d7",
   "metadata": {},
   "source": [
    "# Algorytm MICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7046a16-5d07-4458-8dfc-6a2f97c6159a",
   "metadata": {},
   "source": [
    "1. Wszystkie brakujące wartości są zastępowane pojedynczą\r\n",
    "imputacją.\r\n",
    "2. Dla wybranej zmiennej imputowane wartości są ponownie\r\n",
    "zastępowane brakami.\r\n",
    "3. Tworzony jest model regresyjny dla wartości wybranej\r\n",
    "zmiennej w oparciu o wartości pozostałych zmiennych.\r\n",
    "4. Braki zmiennej są zastępowane wynikami modelu regresyjnego.\r\n",
    "5. Kroki 2-4 są powtarzane raz dla każdej zmiennej z brakami.\r\n",
    "6. Kroki 1-5 są powtarzane przez ustaloną liczbę cykli."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80f0bf-b09f-4afb-8502-ccecca0db79c",
   "metadata": {},
   "source": [
    "Drzewo zbudowane na podstawie danych z brakującymi danymi uzupełnionymi z użyciem metody MICE z 5 iteracjami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa2a15-6a10-422b-b369-2324a7de8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer = IterativeImputer(max_iter=5, random_state=0)\n",
    "df4 = pd.DataFrame(imputer.fit_transform(df))\n",
    "zad4 = create_tree(df4.iloc[:,1:], df4.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4da05a-8875-420e-a31a-c7a803f29160",
   "metadata": {},
   "source": [
    "Drzewo zbudowane na podstawie danych z brakującymi danymi uzupełnionymi z użyciem metody MICE z 5 iteracjami. Zastosuj inputację prostą metodą CART i sekwencję monotonną. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851264a4-47bc-44ca-bcd6-554a4d7f3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(random_state=0)\n",
    "imputer = IterativeImputer(estimator = dtr, max_iter=5, random_state=0, imputation_order = 'ascending')\n",
    "df4 = pd.DataFrame(imputer.fit_transform(df))\n",
    "zad4 = create_tree(df4.iloc[:,1:], df4.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2b733-318d-4eb9-9bfa-b960bcfbdb0a",
   "metadata": {},
   "source": [
    "# 3 laby oceniane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32222040-654e-4cf7-8286-031e0a75773f",
   "metadata": {},
   "source": [
    "# Dla danych z pliku FEB15.csv wylicz wielkość próbki potrzebnej do szacowania średniej\n",
    "# prędkości AverageSpeed.\n",
    "# Sprawdź wyniki dla Z = 0.05 i E = 0.05 oraz E = 0.01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ce803-9ac8-436e-8505-3b65eef0fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_size(s,Z,E, answer_coeffs = 1):\n",
    "    n = Z**2 * s**2/E**2\n",
    "    return math.ceil(n)\n",
    "\n",
    "Z = 0.05\n",
    "E = 0.01\n",
    "s = df['AverageSpeed'].std()\n",
    "\n",
    "n = sample_size(s,Z,E, answer_coeffs = 1)\n",
    "\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e311ff-62c7-4be6-9078-595ce387cda0",
   "metadata": {},
   "source": [
    "Dla danych z pliku FEB15.csv załóż, że poprawne pomiary to te, dla których DataQuality wynosi 1.\n",
    "    \n",
    "Na tej podstawie wylicz współczynnik odpowiedzi.\n",
    "\n",
    "Wylicz rozmiar próbki, którą należy zebrać dla parametrów Z = 0.05 i E = 0.01 uwzględniając\n",
    "współczynnik odpowiedzi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24cd1c7-bb3b-49b2-9888-22a8acaa4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['DataQuality'] == 1]\n",
    "s = df2['AverageSpeed'].std()\n",
    "ans = len(df2)/len(df)\n",
    "print('ans_coefs=',ans)\n",
    "n = sample_size(s,Z = 0.05,E = 0.01, answer_coeffs = ans)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0997744e-7dfa-4215-907f-92b32c28b06c",
   "metadata": {},
   "source": [
    "Przygotuj zbiór danych według następujących instrukcji.\n",
    "\n",
    "Dane z pliku FEB15.csv podziel na zbiór uczący i testowy względem mediany daty Date.\n",
    "\n",
    "Ze zbioru uczącego wylosuj próbkę danych o rozmiarze wyliczonym w poprzednim ćwiczeniu,\n",
    "uwzględniając współczynnik odpowiedzi (przyjmij parametr random_state=100).\n",
    "\n",
    "Ze zbioru testowego i z utworzonej próbki usuń elementy, dla których DataQuality jest różne od 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e75d67-d801-4f1f-b631-534f43be4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # konwersja kolumny Date do typu porządkowego\n",
    "    df['Date'] = pd.to_datetime(df['Date']).apply(lambda x: x.toordinal())\n",
    "    date_median = df['Date'].median()\n",
    "    df_train = df[df['Date'] <= date_median]\n",
    "    df_test = df[df['Date'] > date_median]\n",
    "\n",
    "    # Próbka losowa\n",
    "    sample = df_train.sample(n, random_state = 100)\n",
    "    sample = sample[sample['DataQuality'] == 1]\n",
    "    test = df_test[df_test['DataQuality'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d9067-4ae8-4029-8db1-4899b6dccee5",
   "metadata": {},
   "source": [
    "Funkcja pomocnicza do tworzenia drzew dla poniższych zadań"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b7f83-8601-4f00-a776-32c98a133081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def create_tree(x_train, x_test, y_train, y_test, depth = 5):\n",
    "\n",
    "    clf = DecisionTreeRegressor(random_state=1, max_depth=depth)\n",
    "    clf.fit(x_train, y_train)\n",
    "    err = clf.predict(x_test)-y_test #(tablica błedów dla poszczególnych próbek)\n",
    "    MAE = round(np.mean(np.abs(err)),2) # Mean absolute error\n",
    "    RMSE = round(np.sqrt(((clf.predict(x_test)-y_test)**2).mean()),2) # Root Mean Squared Error\n",
    "    print(\"MAE:\", MAE, \"RMSE:\", RMSE)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179f9b5c-b2fd-4d79-82b4-386c5b6382f5",
   "metadata": {},
   "source": [
    "Dla przygotowanego zbioru danych zbuduj drzewo decyzyjne (o maksymalnej wysokości 5)\n",
    "estymujące średnią prędkość AverageSpeed na podstawie zmiennych Date,TimePeriod i\n",
    "LinkLength.\n",
    "\n",
    "Drzewo wytrenuj na stworzonej próbce danych.\n",
    "    \n",
    "Oblicz błąd średni drzewa uzyskany na danych testowych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287811e-3336-427e-82c0-b591a5d8a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "    features = ['Date', 'TimePeriod', 'LinkLength']\n",
    "    x_train_4 = sample[features]\n",
    "    y_train_4 = sample['AverageSpeed']\n",
    "    x_test = test[features]\n",
    "    y_test = test['AverageSpeed']\n",
    "    print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb0b49-9cab-4f74-9afd-f3548fe47603",
   "metadata": {},
   "source": [
    "Powtórz przygotowanie zbioru danych, ale dobieraj próbkę ze zbioru uczącego sekwencyjnie, w\n",
    "równych odstępach.\n",
    "    \n",
    "Zbuduj drzewo decyzyjne (o maksymalnej wysokości 5) estymujące średnią prędkość\n",
    "AverageSpeed na podstawie zmiennych Date,TimePeriod i LinkLength.\n",
    "\n",
    "Drzewo wytrenuj na stworzonej próbce danych.\n",
    "\n",
    "Oblicz błąd średni drzewa uzyskany na danych testowych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48137a-d611-431e-b33f-6890066452f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probka sekwencyjna\n",
    "seq = [x for x in range(0, len(df_train), round(len(df_train)/n))]\n",
    "sample5 = df_train.iloc[seq,:]\n",
    "sample5 = sample5[sample5['DataQuality'] == 1]\n",
    "X_train5 = sample5[features]\n",
    "Y_train5 = sample5['AverageSpeed']\n",
    "tr5 = create_tree(X_train5, x_test, Y_train5, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415cb96d-0c2e-4435-a2ae-8196200882cc",
   "metadata": {},
   "source": [
    "Powtórz przygotowanie zbioru danych, ale dobieraj próbkę stratyfikacyjnie, dobierając taką samą\n",
    "liczbę odczytów dla każdego odcinka autostrady LinkRef.\n",
    "\n",
    "Jeżeli dla któregoś odcinka brakuje danych to zastosuj próbkowanie z powtórzeniami.\n",
    "\n",
    "Zbuduj drzewo decyzyjne (o maksymalnej wysokości 5) estymujące średnią prędkość\n",
    "AverageSpeed na podstawie zmiennych Date,TimePeriod i LinkLength.\n",
    "\n",
    "Drzewo wytrenuj na stworzonej próbce danych.\n",
    "\n",
    "Oblicz błąd średni drzewa uzyskany na danych testowych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c26313-aed2-4511-a636-859fd364b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probka stratyfikacyjna\n",
    "links = df['LinkRef'].unique()\n",
    "n_gr = round(n/len(links))\n",
    "sample6 = pd.DataFrame([])\n",
    "for k in links:\n",
    "    t = df_train[df_train['LinkRef'] == k]\n",
    "    if len(t) > 0:\n",
    "        tr = t.sample(n = n_gr, random_state = 100, replace = len(t)<n_gr)\n",
    "        sample6 = pd.concat([sample6,tr])\n",
    "sample6 = sample6[sample6['DataQuality'] == 1]\n",
    "X_train6 = sample6[features]\n",
    "Y_train6 =  sample6['AverageSpeed']\n",
    "tr6 = create_tree(X_train6, x_test,Y_train6, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3faaf-bae1-4616-83a3-00af629453d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03213d18-9e0c-4fe5-bd9a-5a2156a8beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bb604-cee0-4632-aff4-0c09639559eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from mlxtend.evaluate import BootstrapOutOfBag\n",
    "#from mlxtend.evaluate import bootstrap_point632_score\n",
    "#from mlxtend.evaluate import bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f4f88-b064-4b45-8d71-7e07b27f45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(x_train, x_test, y_train, y_test, depth=3):\n",
    "    clf = DecisionTreeRegressor(max_depth=depth, random_state=1)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    err = abs(clf.predict(x_test)-y_test)\n",
    "    MAE = round(np.mean(err),2)\n",
    "    RMSE = round(np.sqrt(((clf.predict(x_test)-y_test)**2).mean()),2)\n",
    "    print(\"MAE:\", MAE, \"RMSE:\", RMSE)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d5267-b825-41e3-8d07-1dca8a9ff13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mfeb15.csv',sep=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596df6e2-c4c6-4ddb-a7fb-41952473dfe7",
   "metadata": {},
   "source": [
    "Dla danych z pliku mfeb15.csv oszacuj średnią prędkości AverageSpeed używając\n",
    "zmiennych Date, TimePeriod i LinkLength.\n",
    "\n",
    "Do zbioru uczącego wybierz rekordy isLearning=TRUE.\n",
    "\n",
    "Zbuduj referencyjny model testujący nie stosując żadnych specjalnych metod\n",
    "estymacji.\n",
    "\n",
    "Jako algorytm uczenia maszynowego wybierz drzewo decyzyjne rpart (w Pythonie\n",
    "sklearn.tree.DecisionTreeRegressor).\n",
    "\n",
    "Przetestuj wyniki modelu dla zbioru testowego isLearning=FALSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5777008-c684-4eb4-b082-1eec3ee5e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e14fff-7798-45ff-9798-69d5feced317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df['Date'].astype('datetime64[ns]').apply(lambda x: x.toordinal())\n",
    "#train,test = train_test_split(df, test_size=0.2)\n",
    "train = df.loc[df[\"isLearning\"] == True]\n",
    "test = df.loc[df[\"isLearning\"] == False]\n",
    "print(train)\n",
    "print(test)\n",
    "\n",
    "x_train = train[[\"TimePeriod\",\"Date\",\"LinkLength\"]]\n",
    "y_train = train[\"AverageSpeed\"]\n",
    "x_test = test[[\"TimePeriod\",\"Date\",\"LinkLength\"]]\n",
    "y_test = test[\"AverageSpeed\"]\n",
    "err = create_tree(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61374a01-d23a-47a3-be08-c914e4a97922",
   "metadata": {},
   "source": [
    "Powtórz poprzednie zadanie stosując metody:\n",
    "\n",
    "    o cv krosswalidacja (dla n=10)\n",
    "\n",
    "    o LOOCV Leave-one-out cross-validation\n",
    "\n",
    "    o boot Estymator błędu prób bootstrapowych\n",
    "\n",
    "    o boot632 Estymator .632 (nie ma w Pythonie)\n",
    "\n",
    "Porównaj uzyskane wyniki ze zbiorem referencyjnym. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd39366-5b27-425d-b4e0-f909a1d3b78f",
   "metadata": {},
   "source": [
    "The idea: use different methods for train test split of (\"is_learning\" == True) dataset. Then train model on each split and select the best one. Lastly, use the best one to predict on test set (\"is_learning\" = False) and save the absolute errors.\n",
    "\n",
    " - cross_validate sklearn function: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html\n",
    "\n",
    " - possible scoring arguments: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d9ef0-2415-465e-b3bf-3ba0376259eb",
   "metadata": {},
   "source": [
    "model = DecisionTreeRegressor(max_depth = 3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa19a0a-95df-41bc-ac4d-336f336659f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Fold\n",
    "scores1 = cross_validate(model,x_train,y_train,cv=KFold(10),n_jobs=-1,scoring='neg_mean_absolute_error',return_estimator = True)\n",
    "err1 = abs(scores1['estimator'][scores1[\"test_score\"].argmax()].predict(x_test) - y_test)\n",
    "err1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994ba96-ae1d-4969-b6bd-6a75f12f96a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LeaveOneOut CrossValidation with negative mean absolute scores: the higher the scores, the lower mean absolute errors\n",
    "scores2 = cross_validate(model,x_train,y_train,cv=LeaveOneOut(),n_jobs=-1,scoring='neg_mean_absolute_error',return_estimator = True)\n",
    "err2 = abs(scores2['estimator'][scores2[\"test_score\"].argmax()].predict(x_test) - y_test)\n",
    "err2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75f580-7368-47a3-a0e0-addd646547b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bootstrap Out of Bag\n",
    "scores3 = cross_validate(model,x_train,y_train,cv=BootstrapOutOfBag(n_splits = 10,random_seed = 1),n_jobs=-1,scoring='neg_mean_absolute_error',return_estimator = True)\n",
    "err3 = abs(scores3['estimator'][scores3[\"test_score\"].argmax()].predict(x_test) - y_test)\n",
    "err3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d773dc-e5b4-4f0c-8f07-026a0e2fe705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeated K-Fold\n",
    "scores4 = cross_validate(model,x_train,y_train,cv=RepeatedKFold(),n_jobs=-1,scoring='neg_mean_absolute_error',return_estimator = True)\n",
    "err4 = abs(scores4['estimator'][scores4[\"test_score\"].argmax()].predict(x_test) - y_test)\n",
    "err4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d7885-aee7-4c59-99cf-d5cb8d5d27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_err = pd.concat ([pd.DataFrame({'Err': err1, 'Type': 'KFold CV'}),\n",
    "                    pd.DataFrame({'Err': err2, 'Type': 'LOO CV'}),\n",
    "                     pd.DataFrame({'Err': err3, 'Type': 'BOOTOOB'}),\n",
    "                     pd.DataFrame({'Err': err4, 'Type': 'Repeated KFold'}),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa438aa-1f31-4a4e-9c37-2008a9dc8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "g = sns.boxplot(data = d_err, y = \"Err\", x= \"Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a85d58-4e4e-45ce-8a98-566401baf778",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = d_err.groupby('Type').describe().round(2)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff1e83-8d11-47fd-b075-c22a0832e810",
   "metadata": {},
   "source": [
    "• Powtórz poprzednie zadania dla lasów losowych.\n",
    "    \n",
    "• Porównaj otrzymane wyniki, aby odpowiedzieć na pytania:\n",
    "\n",
    "    o Która metoda daje lepsze wyniki (drzewo czy las)?\n",
    "\n",
    "    o Który sposób uczenia daje lepsze wyniki? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa24e2-6e39-4e28-a9c4-9ed442adde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bfa97a-0470-4b41-b94d-21ddc4b07a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestRegressor(max_depth = 3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20945e74-bf60-44ad-9fff-4023b7166c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Fold\n",
    "scores1ref = cross_validate(model_rf,x_train,y_train,cv=KFold(10),n_jobs=-1,scoring='neg_mean_absolute_error',return_estimator = True)\n",
    "err1ref = abs(scores1ref['estimator'][scores1[\"test_score\"].argmax()].predict(x_test) - y_test)\n",
    "err1ref\n",
    "#LeaveOneOut CrossValidation with negative mean absolute scores: the higher the scores, the lower mean absolute errors\n",
    "scores2ref = cross_validate(model_rf,x_train,y_train,cv=LeaveOneOut(),n_jobs=-1,scoring='neg_mean_absolute_error',return_estimator = True)\n",
    "err2ref = abs(scores2ref['estimator'][scores2ref[\"test_score\"].argmax()].predict(x_test) - y_test)\n",
    "err2ref\n",
    "#Bootstrap Out of Bag\n",
    "scores3ref = cross_validate(model_rf,x_train,y_train,cv=BootstrapOutOfBag(n_splits = 10,random_seed = 1),n_jobs=-1,scoring='neg_mean_absolute_error',return_estimator = True)\n",
    "err3ref = abs(scores3ref['estimator'][scores3ref[\"test_score\"].argmax()].predict(x_test) - y_test)\n",
    "err3ref\n",
    "#Repeated K-Fold\n",
    "scores4ref = cross_validate(model_rf,x_train,y_train,cv=RepeatedKFold(),n_jobs=-1,scoring='neg_mean_absolute_error',return_estimator = True)\n",
    "err4ref = abs(scores4ref['estimator'][scores4ref[\"test_score\"].argmax()].predict(x_test) - y_test)\n",
    "err4ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c75024-3c47-4db1-8d31-1b8203596bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are able to get mean square errors for bootstrap oob and .632. However, we don't have the model specs and the errors\n",
    "#scores5 = bootstrap_point632_score(model, X_train, Y_train, method='oob')\n",
    "#scores6 = bootstrap_point632_score(model, X_train, Y_train, method='.632')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de501cf1-8636-48fd-8aae-b62ef95c4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_errref = pd.concat ([pd.DataFrame({'Err': err1ref, 'Type': 'KFold CV'}),\n",
    "                    pd.DataFrame({'Err': err2ref, 'Type': 'LOO CV'}),\n",
    "                     pd.DataFrame({'Err': err3ref, 'Type': 'BOOTOOB'}),\n",
    "                     pd.DataFrame({'Err': err4ref, 'Type': 'Repeated KFold'}),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6ebbc-5e9e-4ae5-8144-dfec39b90bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "g = sns.boxplot(data=d_errref, y = 'Err', x= 'Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b31085-a0e1-48f3-9e55-dcdd3f7d22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "statsref = d_errref.groupby('Type').describe().round(2)\n",
    "statsref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdee133-e613-40c6-ae8b-ccaea8064351",
   "metadata": {},
   "source": [
    "# Wczytaj zbiór iris i usuń z niego klasę setosa. \n",
    "# Następnie, korzystając z 10-krotnej kroswalidacji, wylicz wyniki predykcji Species dla\n",
    "# metod\n",
    "# Native Bayes \n",
    "# Multi Layer Perceptron\n",
    "# Decision Tree (rpart) \n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c811cd1-c07e-4e2b-b4f2-934d750af3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "#print(iris)\n",
    "df = pd.DataFrame(iris.data)\n",
    "#print(df)\n",
    "df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "#print(df)\n",
    "df['species'] = iris.target\n",
    "df4 = df.copy()\n",
    "#print(df)\n",
    "df.loc[df['species']==0, 'species'] = 'setosa'\n",
    "df.loc[df['species']==1, 'species'] = 'versicolor'\n",
    "df.loc[df['species']==2, 'species'] = 'virginica'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b604408-fae1-46a5-90a6-e6cd5ad2bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['species'] != 'setosa']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7984c03-c185-4816-a2ff-5b7bbb1b711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "target = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d820e-cbd5-4e2a-a10b-470f1b793a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, features, target):\n",
    "    predicted = cross_val_predict(model, features, target, cv=10)\n",
    "    predicted2 = cross_val_predict(model, features, target, cv=10, method = 'predict_proba')\n",
    "    acc_res = cross_val_score(model, features, target, cv=10, scoring = 'accuracy', n_jobs = 1)\n",
    "    \n",
    "    acc = accuracy_score(target, predicted)\n",
    "    f1 = f1_score(target, predicted, pos_label='virginica')\n",
    "    fpr, tpr, tresholds = roc_curve(target, predicted2.T[1], pos_label='virginica')\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    cm = confusion_matrix(target, predicted)\n",
    "    \n",
    "    print('Accuracy =' , acc.round(3))\n",
    "    print('F1       =' , f1.round(3))\n",
    "    print('ROC_AUC  =' , roc_auc.round(3))\n",
    "    print('Confusion matrix:\\n =' , cm)\n",
    "    \n",
    "    return(acc, f1, roc_auc, acc_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b82b31-a038-4343-976a-cd47c18a7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "NB = model_eval(model, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a4cd8-5dd5-4fc3-a5aa-8807b46ab378",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(max_iter = 1000, random_state = RANDOM_STATE)\n",
    "mlp = model_eval(model, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387bdfd-94b8-42b1-bfc9-0afb1b966012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = RANDOM_STATE)\n",
    "dtc = model_eval(model, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb66b8-2c70-425a-9226-87114a851dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth = 2, random_state = RANDOM_STATE)\n",
    "rfc = model_eval(model, features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09754770-b0dd-4c6f-9572-507c3c18643d",
   "metadata": {},
   "source": [
    "# Odczytaj wyniki skuteczności z 10 testów kroswalidacji dla klasyfikatorów dających\n",
    "# najniższą i najwyższą skuteczność. \n",
    "# Sprawdź, czy różnice między ich skutecznością są statystycznie istotne.\n",
    "# Przyjmij poziom istotności 0.05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd61ee9-144e-423d-9396-7a6d1cbe2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d69be3-b0f1-48a2-808e-0e7ea84c7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstudent = ttest_ind(dtc[3], mlp[3])\n",
    "print(\"p-value: \", tstudent.pvalue.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6764061-c751-480c-a8e0-3cd1ebcce51a",
   "metadata": {},
   "source": [
    "# Wykonaj 10-krotną kroswalidację dla lasu losowego i regresji grzbietowej, aby\n",
    "# wyliczyć Sepal_Length \n",
    "# Wylicz błędy uzyskane dla obu metod\n",
    "# Przeprowadź testy statystyczne, aby sprawdzić czy na poziomie istotności 0.05 \n",
    "# Rozkłady błędów są różne\n",
    "# Jeden model regresji daje mniejsze błędy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d7d01-3d1f-46ac-8eca-b65a1fd8e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c7003-8223-4191-a0ec-16ddab0ddf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df4[['species', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "target = df4['sepal_length']\n",
    "clf = RandomForestRegressor()\n",
    "pred_rf = cross_val_predict(clf, features, target, cv = 10)\n",
    "err_rf = abs(pred_rf - target)\n",
    "print(\"mean error RF: \", np.mean(err_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23373cde-c531-4896-9c38-f9904792b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Ridge(alpha=1.0)\n",
    "pred_ridge = cross_val_predict(clf, features, target, cv = 10)\n",
    "err_ridge = abs(pred_ridge - target)\n",
    "print(\"mean error RF: \", np.mean(err_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76f0db-3d2b-4e88-aa1e-06e2a6dfd5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = wilcoxon(err_rf, err_ridge, alternative= 'two-sided')\n",
    "print(\"wilcoxon two-sided p-value: \", res1.pvalue)\n",
    "res2= wilcoxon(err_rf, err_ridge, alternative= 'greater')\n",
    "print(\"wilcoxon greater p-value: \", res2.pvalue)\n",
    "res3= wilcoxon(err_rf, err_ridge, alternative= 'less')\n",
    "print(\"wilcoxon less p-value: \", res3.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ab331-5b9b-40a2-8c18-0d3efaa3f899",
   "metadata": {},
   "source": [
    "# Wczytaj zbiór Glass i zostaw w nim tylko przedstawicieli klas (kolumna Type) 2 i 3. \n",
    "# Nadaj klasom oznaczenia 0 i 1. \n",
    "# Podziel losowo zbiór na testowy i uczący w stosunku 1:1. \n",
    "# Upewnij się, ze rozkład klas w zbiorze uczącym i testowym są podobne.\n",
    "# Zbuduj klasyfikator, las losowy złożony z 30 drzew, który rozróżnia obie klasy.\n",
    "# Sprawdź skuteczność i zbalansowaną skuteczność tego klasyfikatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc911d15-995e-4c31-8d0c-3b003b288351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b4571-5396-43ff-bf94-327f6338f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('glass.csv')\n",
    "df = df[df['Type'].isin([2,3])]\n",
    "\n",
    "df.loc[df['Type'] == 2.0, 'Type'] = 0\n",
    "df.loc[df['Type'] == 3.0, 'Type'] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d182e2-35c5-4c73-9847-d3d1f3c1e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.loc[:, df.columns != 'Type' ]\n",
    "y = df['Type']        \n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.5, random_state = RANDOM_STATE)\n",
    "print('overall:  ', len(y), ' ', len(y[y==1]), ' ', len(y[y==1])/len(y))\n",
    "print('train:  ', len(y_train), ' ', len(y_train[y_train==1]), ' ', len(y_train[y_train==1])/len(y_train))\n",
    "print('test:  ', len(y_test), ' ', len(y_test[y_test==1]), ' ', len(y_test[y_test==1])/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e59f8-74c2-405b-b75b-0b6cdffa2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=30, random_state=RANDOM_STATE)\n",
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "print('Accuracy:           ', accuracy_score(y_test, predicted).round(3))\n",
    "print('Balanced accuracy:  ', balanced_accuracy_score(y_test, predicted).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c2fac-9f31-4a14-96e6-bb4b9a955dd8",
   "metadata": {},
   "source": [
    "# Przekształć zbiór uczący algorytmem ROSE (Random Over Sampling Examples).\n",
    "# Utwórz las losowy zbudowany z 30 drzew, który rozróżnia obie klasy, ucząc go na\n",
    "# nowych danych, ale testując na niezmodyfikowanym zbiorze testowym. \n",
    "# Sprawdź skuteczność i zbalansowaną skuteczność tego klasyfikatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fcdcd4-9a8f-46bc-9321-2e0c15d01690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122fe3c0-4369-4c6b-b015-ae67672d5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "x_res, y_res = ros.fit_resample(x_train, y_train)\n",
    "print('train ROSE:  ', len(y_res), ' ', len(y_res[y_res==1]), ' ', len(y_res[y_res==1])/len(y_res))\n",
    "model = RandomForestClassifier(n_estimators=30, random_state=RANDOM_STATE)\n",
    "model.fit(x_res, y_res)\n",
    "predicted = model.predict(x_test)\n",
    "print('Accuracy:           ', accuracy_score(y_test, predicted).round(3))\n",
    "print('Balanced accuracy:  ', balanced_accuracy_score(y_test, predicted).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b95ea0-e804-485e-a0ab-f6d8b071e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dla nieprzekształconego zbioru uczącego i testowego zastosuj algorytm RUSBoost\n",
    "# Do budowy klasyfikatora uzyj 30 drzew decyzyjnych c50 jako słabe klasyfikatory\n",
    "# Sprawdź skuteczność i zbalansowaną skuteczność tego klasyfikatora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b78e8b-b774-4ca0-b769-1509d6c43e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076755f-6deb-4738-baf9-a98ced441a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RUSBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=30, algorithm = 'SAMME', random_state=RANDOM_STATE)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "predicted = clf.predict(x_test)\n",
    "print('Accuracy:           ', accuracy_score(y_test, predicted).round(3))\n",
    "print('Balanced accuracy:  ', balanced_accuracy_score(y_test, predicted).round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
